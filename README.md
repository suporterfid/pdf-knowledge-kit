# PDF/Markdown â†’ Vector DB (pgvector) Starter Kit

Crie rapidamente uma base de conhecimento a partir de **arquivos PDF** e **Markdown** em uma pasta local e habilite **busca semÃ¢ntica** para um agente de IA.

Inclui uma interface web inspirada no ChatGPT com histÃ³rico de conversas, anexos, destaque de cÃ³digo e alternÃ¢ncia de tema claro/escuro.

## VisÃ£o geral
1. **Extrai** textos dos PDFs e arquivos Markdown.
2. **Divide** em *chunks* (trechos) com sobreposiÃ§Ã£o.
3. **Gera embeddings** (multilÃ­ngue, PT/EN) com `fastembed`.
4. **Armazena** em **PostgreSQL + pgvector**.
5. **Consulta** por similaridade (kNN) com `query.py` â€” pronto para integrar no seu agente.

> DimensÃ£o dos vetores: **384** (modelo `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`).

### Suporte a idiomas
O modelo `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` atende mais de 50 idiomas
e foi verificado com frases em **inglÃªs**, **portuguÃªs brasileiro** e **espanhol**.
LÃ­nguas fora desse conjunto podem gerar embeddings de qualidade reduzida e
resultados menos precisos.

---

## Requisitos
- **Docker** + **Docker Compose** (para o Postgres com pgvector).
- **Python 3.10+** com `pip`.
- *(Opcional p/ OCR)* `tesseract-ocr`, pacotes de idioma (`tesseract-ocr-eng`, `tesseract-ocr-por`, `tesseract-ocr-spa`) e `poppler-utils`.
O `Dockerfile` jÃ¡ instala esses pacotes.

## Ambiente de desenvolvimento
1. Clone este repositÃ³rio.
2. Crie um ambiente virtual e instale as dependÃªncias:
```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```
3. Suba o Postgres local com pgvector:
```bash
docker compose up -d db
```
4. Execute os testes para validar o setup:
```bash
pytest
```
5. Inicie o backend em modo `reload`:
```bash
uvicorn app.main:app --reload
```
6. (Opcional) Para a interface web estilo ChatGPT (histÃ³rico, anexos, temas), entre em `frontend/` e rode `npm install && npm run dev`.

## Passo a passo (rÃ¡pido)
```bash
# 1) Suba o Postgres com pgvector
docker compose up -d db

# 2) Instale as dependÃªncias Python
python -m venv .venv && source .venv/bin/activate  # no Windows: .venv\Scripts\activate
pip install -r requirements.txt

# 3) Configure variÃ¡veis de ambiente (opcional)
cp .env.example .env  # edite se quiser

# 4) Coloque seus PDFs e arquivos Markdown (.md) na pasta ./docs/
#    Arquivos .md nessa pasta sÃ£o ingeridos junto com os PDFs
#    (ou aponte outra pasta com --docs / DOCS_DIR)

# 5) IngestÃ£o
python ingest.py --docs ./docs  # use --ocr (ex.: --ocr-lang eng+por) ou ENABLE_OCR=1 para PDFs escaneados

# 6) Consulta (exemplo)
python query.py --q "Como configuro potÃªncia de leitura?" --k 5
```

## IngestÃ£o de PDFs/Markdown com Docker

1. **Tornar os arquivos acessÃ­veis ao container**

   - Coloque os arquivos na pasta `docs/` do projeto.
   - Essa pasta jÃ¡ estÃ¡ mapeada dentro do container; tudo nela ficarÃ¡ disponÃ­vel em `/app/docs` quando o serviÃ§o subir.

2. **Ingerir os arquivos no banco**

   No diretÃ³rio raiz do projeto, execute:

   ```bash
   docker compose run --rm app python ingest.py --docs /app/docs  # adicione --ocr/--ocr-lang ou ENABLE_OCR=1 se preciso
   ```

   Esse script lÃª os PDFs e arquivos Markdown e grava os vetores no **PostgreSQL/pgvector**.

3. **Subir a aplicaÃ§Ã£o**

   Inicie os serviÃ§os normalmente:

   ```bash
   docker compose up --build
   ```

   Isso lanÃ§a o backend e o frontend, que jÃ¡ podem consultar os documentos ingeridos.

4. **(Opcional) Usar outra pasta local**

   Se preferir outra pasta, **antes** de subir os containers, altere o mapeamento de volume em `docker-compose.yml` para apontar para o diretÃ³rio desejado.

   Exemplo para Windows:

   ```yaml
   volumes:
     - C:/Users/alexa/Dropbox/Delivery/Impinj/R700/FAQ:/app/docs:ro
   ```

   Depois, rode a ingestÃ£o:

   ```bash
   docker compose run --rm app python ingest.py --docs /app/docs  # adicione --ocr/--ocr-lang ou ENABLE_OCR=1 se preciso
   ```

   Ou mapeie o volume diretamente na execuÃ§Ã£o:

   ```bash
   docker compose run --rm \
     -v "C:/Users/alexa/Dropbox/Delivery/Impinj/R700/FAQ:/app/docs:ro" \
    app python ingest.py --docs /app/docs  # adicione --ocr ou ENABLE_OCR=1 se preciso
   ```


## IngestÃ£o de pÃ¡ginas web pÃºblicas

AlÃ©m de arquivos locais, o `ingest.py` tambÃ©m pode buscar e indexar pÃ¡ginas da web acessÃ­veis publicamente.

```bash
# Uma ou mais URLs diretamente na linha de comando
python ingest.py --url https://exemplo.com/sobre --url https://example.com/en/doc

# Lista de URLs (uma por linha)
python ingest.py --urls-file urls.txt
# ou defina URLS_FILE=urls.txt e o script usarÃ¡ esse caminho por padrÃ£o
```

O conteÃºdo dessas pÃ¡ginas deve estar em **inglÃªs**, **portuguÃªs** ou **espanhol** (EN/PT/ES).

## Logging

A aplicaÃ§Ã£o grava dois arquivos de log em `LOG_DIR` (padrÃ£o `logs/` localmente):

- `app.log` â€“ eventos da aplicaÃ§Ã£o.
- `access.log` â€“ requisiÃ§Ãµes/respostas HTTP.

Os arquivos sÃ£o **rotacionados diariamente Ã  meia-noite** e mantidos por `LOG_RETENTION_DAYS` dias (padrÃ£o: 7).
Defina `LOG_ROTATE_UTC=true` para rotacionar em UTC.

Principais variÃ¡veis de ambiente:

| VariÃ¡vel              | PadrÃ£o    | DescriÃ§Ã£o |
|----------------------|-----------|-----------|
| `LOG_DIR`            | `logs/`   | DiretÃ³rio dos arquivos de log (no Docker: `/var/log/app`). |
| `LOG_LEVEL`          | `INFO`    | NÃ­vel mÃ­nimo de log. |
| `LOG_JSON`           | `false`   | SaÃ­da em formato JSON. |
| `LOG_REQUEST_BODIES` | `false`   | Inclui corpo da requisiÃ§Ã£o no access log. |
| `LOG_RETENTION_DAYS` | `7`       | Quantidade de dias mantidos apÃ³s rotaÃ§Ã£o. |
| `LOG_ROTATE_UTC`     | `false`   | Rotaciona usando UTC. |

Para verificar rapidamente os valores efetivos dessas configuraÃ§Ãµes, execute:

```bash
python -m tools.print_log_config
```

### Tailing logs

```bash
# Local
tail -f logs/app.log

# Docker
docker compose logs -f app
docker compose exec app tail -f /var/log/app/app.log
```

Para persistir os logs dos containers no host, mapeie um volume:

```yaml
app:
  volumes:
    - ./logs:/var/log/app
```

## MÃ©tricas

A aplicaÃ§Ã£o expÃµe mÃ©tricas no formato **Prometheus** em `/api/metrics`.
Ao rodar localmente ou via Docker, vocÃª pode verificar as mÃ©tricas com:

```bash
curl http://localhost:8000/api/metrics
```

Esses dados podem ser coletados por Prometheus ou outras ferramentas de monitoramento.

## Build do chat e frontend


## DepuraÃ§Ã£o com VS Code + Docker Desktop

Use as configuraÃ§Ãµes jÃ¡ incluÃ­das em `.vscode/launch.json` para depurar o stack completo:

- Abra o projeto no VS Code e certifique-se de que o Docker Desktop estÃ¡ em execuÃ§Ã£o.
- Pressione F5 e selecione "Fullstack: Backend + Frontend".
  - O VS Code executa `docker compose up -d --build` (db, backend e frontend).
  - O backend inicia com `debugpy` ouvindo em `5678` (nÃ£o bloqueia a API). VocÃª pode anexar a qualquer momento.
  - O VS Code se anexa ao backend (mapeamento de cÃ³digo fonte `/app` â‡„ workspace).
  - O Chrome Ã© aberto em `http://localhost:5173` (Vite) para depuraÃ§Ã£o do React.

TambÃ©m Ã© possÃ­vel iniciar individualmente:

- "Backend: Attach FastAPI (Docker)" para apenas o backend.
- "Frontend: Launch Chrome (Vite)" para apenas o frontend.

ObservaÃ§Ãµes:

- Hot reload habilitado: `uvicorn --reload` no backend e Vite no frontend.
- Quebre pontos normalmente nos arquivos locais; o mapeamento com os containers jÃ¡ estÃ¡ configurado.
- ApÃ³s a sessÃ£o, vocÃª pode parar os serviÃ§os com a tarefa `compose: down` no VS Code (Terminal > Run Task).

```bash
# Backend standalone
uvicorn app.main:app --reload  # roda em http://localhost:8000

# ou construa tudo com Docker
docker compose up --build

# Frontend (opcional para alterar a interface)
cd frontend
npm install
npm run build  # gera os arquivos em app/static
```

## VariÃ¡veis de ambiente
Copie `.env.example` para `.env` e ajuste conforme necessÃ¡rio. Exemplo mÃ­nimo:

```env
DOCS_DIR=./docs           # PDFs e Markdown (.md) lidos desta pasta
ENABLE_OCR=0              # OCR sÃ³ para PDFs escaneados (nÃ£o afeta .md)
OCR_LANG=eng+por+spa      # ex.: PDFs em inglÃªs, portuguÃªs e espanhol
```

Principais chaves disponÃ­veis:

- **PGHOST**, **PGPORT**, **PGDATABASE**, **PGUSER**, **PGPASSWORD** â€“ conexÃ£o com o Postgres/pgvector (padrÃµes: `db`, `5432`, `pdfkb`, `pdfkb`, `pdfkb`).
- **DOCS_DIR** â€“ pasta padrÃ£o para os arquivos. Qualquer `.md` nessa pasta Ã© ingerido junto com os PDFs.
  - **OPENAI_API_KEY**, **OPENAI_MODEL**, **OPENAI_LANG**, **SYSTEM_PROMPT**, **USE_LLM** â€“ integraÃ§Ãµes com LLM (opcional). `SYSTEM_PROMPT` permite configurar o tom/persona do agente.
- **TOP_K**, **MAX_CONTEXT_CHARS** â€“ ajustes de recuperaÃ§Ã£o de trechos.
- **UPLOAD_DIR**, **UPLOAD_TTL**, **UPLOAD_MAX_SIZE**, **UPLOAD_MAX_FILES**, **UPLOAD_ALLOWED_MIME_TYPES** â€“ controle de uploads temporÃ¡rios.
- **CORS_ALLOW_ORIGINS**, **BRAND_NAME**, **POWERED_BY_LABEL**, **LOGO_URL** â€“ personalizaÃ§Ã£o da UI. `POWERED_BY_LABEL` define o texto do rodapÃ© (padrÃ£o: "Powered by PDF Knowledge Kit").
- **ENABLE_OCR** â€“ habilita OCR em execuÃ§Ãµes nÃ£o interativas (override de `--ocr`).
- **OCR_LANG** â€“ idiomas do Tesseract para OCR. Combine mÃºltiplos cÃ³digos com `+` (ex.: `eng+por`).

## OCR (Tesseract)

Por padrÃ£o, o OCR usa `OCR_LANG=eng+por+spa` (InglÃªs, PortuguÃªs e Espanhol). Altere os idiomas com `--ocr-lang` ou definindo a variÃ¡vel `OCR_LANG` antes da execuÃ§Ã£o.

### InstalaÃ§Ã£o

Para PDFs escaneados, instale o mecanismo de OCR, os pacotes de idioma e os conversores de PDF (o `Dockerfile` jÃ¡ inclui `tesseract-ocr-eng`, `tesseract-ocr-por` e `tesseract-ocr-spa`):

```bash
# Ubuntu/Debian
sudo apt install tesseract-ocr tesseract-ocr-eng tesseract-ocr-por tesseract-ocr-spa poppler-utils
# macOS (Homebrew)
brew install tesseract poppler
# Ver idiomas disponÃ­veis
tesseract --list-langs
```

### Como habilitar

- **Linha de comando (override):**

  ```bash
  python ingest.py --ocr --ocr-lang eng --docs ./docs
  ```

- **VariÃ¡veis de ambiente (override):**

  ```bash
  ENABLE_OCR=1 OCR_LANG=spa+por python ingest.py --docs ./docs
  ```

### Desempenho e suporte a idiomas

- OCR aumenta o tempo de ingestÃ£o (cada pÃ¡gina Ã© renderizada e processada).
- `OCR_LANG` e `--ocr-lang` aceitam mÃºltiplos cÃ³digos (ex.: `eng+por+spa`). Cada idioma extra deixa o processamento mais lento, mas pode melhorar a precisÃ£o em documentos multilÃ­ngues; instale os pacotes correspondentes.

### SoluÃ§Ã£o de problemas

- `tesseract: command not found` ou `pdftoppm: command not found` â†’ instale `tesseract-ocr` e `poppler-utils` e verifique o `PATH`.
- `Error opening data file` ou `Failed loading language` â†’ o pacote de idioma nÃ£o estÃ¡ instalado. Rode `tesseract --list-langs` e instale, por exemplo, `sudo apt install tesseract-ocr-spa`.

## Uso do chat
1. Garanta que o backend esteja rodando (com `uvicorn` ou Docker).
2. Acesse `http://localhost:8000` no navegador.
3. Envie mensagens pelo campo de texto. Opcionalmente, anexe um PDF pequeno para enriquecer o contexto.
4. Durante a geraÃ§Ã£o da resposta, use **Cancelar** para interromper o streaming e **Enviar** novamente para retomar.

Recursos da interface:
- Barra lateral com histÃ³rico de conversas (criar, renomear, excluir).
- Avatares e bolhas com realce de cÃ³digo via Prism.
- BotÃµes para copiar, regenerar e avaliar cada resposta.
- PrÃ©-visualizaÃ§Ã£o de PDFs anexados.
- AlternÃ¢ncia entre tema claro e escuro.

## Estrutura
```
pdf_knowledge_kit/
â”œâ”€ docker-compose.yml      # Postgres + pgvector
â”œâ”€ requirements.txt        # DependÃªncias
â”œâ”€ schema.sql              # CriaÃ§Ã£o de tabelas/Ã­ndices
â”œâ”€ migrations/             # MigraÃ§Ãµes incrementais do banco de dados
â”œâ”€ ingest.py               # Varre PDFs/Markdown, extrai, fatia e insere
â”œâ”€ query.py                # Busca semÃ¢ntica
â”œâ”€ .env.example            # Configs de conexÃ£o
â””â”€ docs/                   # Coloque seus PDFs e Markdown aqui
```

## Deploy em produÃ§Ã£o

### Bare metal
1. Instale **PostgreSQL** com a extensÃ£o **pgvector** e crie o banco:
```bash
psql -c 'CREATE EXTENSION IF NOT EXISTS vector;' "$PGDATABASE"
psql -f schema.sql "$PGDATABASE"
psql -f migrations/002_add_admin_ingestion.sql "$PGDATABASE"
psql -f migrations/003_extend_ingestion_tables.sql "$PGDATABASE"  # novas colunas de metadados
```
2. Configure as variÃ¡veis de ambiente (veja `.env.example`).
3. Ingestione os documentos:
```bash
python ingest.py --docs ./docs
```
4. Inicie a API com um servidor como **gunicorn** ou **uvicorn**:
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```
5. Teste:
```bash
curl http://localhost:8000/api/health
```

## Debug com Dev Containers (VS Code)

- PrÃ©-requisitos: Docker Desktop; VS Code com extensÃ£o "Dev Containers"; acesso Ã  internet para baixar imagens.
- Abrir no container:
  - Abra a pasta do projeto no VS Code.
  - Paleta de Comandos â†’ "Dev Containers: Reopen in Container" (ou "Rebuild and Reopen in Container").
  - O VS Code usa `.devcontainer/devcontainer.json` + `docker-compose.yml` e sobe `db`, `app` e `frontend`.
- Aguardar o banco ficar healthy:
  - O serviÃ§o `db` fica "healthy" via `pg_isready`; a primeira execuÃ§Ã£o pode demorar por download de imagens.
  - Para um reset completo: `docker compose down -v` e depois `docker compose up -d`.
- Iniciar o debug:
  - Backend: pressione F5 e selecione "Attach to FastAPI (Docker)". O backend jÃ¡ inicia com `debugpy` em `0.0.0.0:5678` e `--wait-for-client`, entÃ£o ele comeÃ§a a rodar apÃ³s o attach. Quebre em `app/` normalmente.
  - Fullâ€‘stack: selecione "Fullstack: Backend + Frontend" para anexar ao backend e abrir o Vite dev server no navegador.
- Portas Ãºteis:
  - API: `http://localhost:8000` (OpenAPI em `/docs`, health em `/api/health`)
  - Frontend: `http://localhost:5173`
  - Debug Python (debugpy): `5678`
- ConexÃ£o ao Postgres nos containers:
  - Use o host `db` (nÃ£o `localhost`). A `.env` jÃ¡ define `PGHOST=db` e `DATABASE_URL=postgresql://pdfkb:pdfkb@db:5432/pdfkb`.
- Dicas rÃ¡pidas:
  - Logs: `docker compose logs -f db app frontend`
  - Shell no container: `docker compose exec app bash`
  - Reset do banco (apaga volume): `docker compose down -v`

### Docker
1. Copie `.env.example` para `.env` e ajuste.
2. Construa e suba os serviÃ§os:
```bash
docker compose up --build -d
```
> Nota (Docker/Dev Containers): dentro dos containers use o host `db` (nÃ£o `localhost`) para acessar o Postgres. A `.env` jÃ¡ define `PGHOST=db` e `DATABASE_URL=postgresql://pdfkb:pdfkb@db:5432/pdfkb`.
3. Ingerir documentos dentro do container:
```bash
docker compose run --rm app python ingest.py --docs /app/docs
```
4. Verifique a API:
```bash
curl http://localhost:8000/api/health
```

## IntegraÃ§Ã£o no seu agente de IA (resumo)
- Use `query.py` como referÃªncia: gere embedding da pergunta e rode SQL:
  `SELECT ... ORDER BY embedding <-> :vec LIMIT :k`.
  - Traga os trechos + metadados e alimente o *prompt* do agente (*RAG*).
  - Para respostas fiÃ©is, **mostre as fontes** (caminho do arquivo e pÃ¡gina, quando houver).

## Respostas humanizadas com OpenAI

O kit pode complementar os trechos retornados com uma resposta em linguagem natural gerada pela API da OpenAI.

1. Configure as variÃ¡veis de ambiente:

```bash
export OPENAI_API_KEY="sua-chave"
export OPENAI_MODEL="gpt-4o-mini"  # ou outro modelo compatÃ­vel
export OPENAI_LANG="pt"            # opcional: forÃ§a o idioma da resposta
```

Se `OPENAI_LANG` nÃ£o for definido, o idioma da pergunta Ã© detectado automaticamente e a resposta Ã© devolvida no mesmo idioma.

### Exemplo (CLI)

```bash
python query.py --q "Â¿CuÃ¡l es la capital de Francia?" --k 3
# Resposta: La capital de Francia es ParÃ­s.
```

### Exemplo (API)

```bash
curl -s -X POST http://localhost:8000/api/ask \
  -H 'Content-Type: application/json' \
  -d '{"q":"Qual Ã© a capital da Alemanha?"}'
```

Resposta:

```json
{"answer": "A capital da Alemanha Ã© Berlim.", "from_llm": true}
```

## Admin Ingestion

The `/api/admin/ingest/*` endpoints let operators trigger ingestion jobs remotely. Jobs run in the background and immediately return a `job_id`. Each job writes its own log file that can be polled while the work proceeds.

### Roles and environment variables

Requests must send an API key in the `X-API-Key` header. Keys map to roles in a strict hierarchy:

- **viewer** â€“ read-only access to jobs and sources.
- **operator** â€“ all viewer permissions plus start and cancel jobs.
- **admin** â€“ reserved for advanced operations.

Configure the keys with single-value environment variables:

```bash
ADMIN_API_KEY=admin    # full access
OP_API_KEY=oper        # start/cancel jobs
VIEW_API_KEY=view      # read-only
```

### Job lifecycle, logs, and monitoring

Jobs move from `pending` â†’ `running` â†’ `completed`/`failed`/`canceled`. Logs are stored per job and exposed via `GET /api/admin/ingest/jobs/<JOB_ID>/logs`. The endpoint returns a slice of text and the next byte offset so clients can poll to tail progress.

```bash
# List jobs
curl -H "X-API-Key: $VIEWER_API_KEY" \
  http://localhost:8000/api/admin/ingest/jobs

# Inspect a single job
curl -H "X-API-Key: $VIEWER_API_KEY" \
  http://localhost:8000/api/admin/ingest/jobs/<JOB_ID>

# Read logs from the beginning
curl -H "X-API-Key: $VIEWER_API_KEY" \
  "http://localhost:8000/api/admin/ingest/jobs/<JOB_ID>/logs?offset=0"

# Cancel a running job
curl -X POST -H "X-API-Key: $OPERATOR_API_KEY" \
  http://localhost:8000/api/admin/ingest/jobs/<JOB_ID>/cancel

# Re-run a job using the same source
curl -X POST -H "X-API-Key: $OPERATOR_API_KEY" \
  http://localhost:8000/api/admin/ingest/jobs/<JOB_ID>/rerun
```

### Ingestion examples

```bash
# Local file
curl -X POST http://localhost:8000/api/admin/ingest/local \
  -H "X-API-Key: $OPERATOR_API_KEY" \
  -d "path=/app/docs/example.pdf"

# Single URL
curl -X POST http://localhost:8000/api/admin/ingest/url \
  -H "X-API-Key: $OPERATOR_API_KEY" \
  -d "url=https://example.com/doc"

# List of URLs
curl -X POST http://localhost:8000/api/admin/ingest/urls \
  -H "X-API-Key: $OPERATOR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"urls": ["https://a.com/doc1", "https://b.com/doc2"]}'
```

### Source management

```bash
# List known sources
curl -H "X-API-Key: $VIEWER_API_KEY" \
  http://localhost:8000/api/admin/ingest/sources
```

### Admin UI

Admin features live under `frontend/src/admin` inside the main frontend project. To work on them, start the frontend dev server and visit the `/admin` route:

```bash
cd frontend
npm install
npm run dev
```

If you need to serve the UI from another origin, set `ADMIN_UI_ORIGINS` before starting the backend so CORS allows the requests.

## Dicas francas
- PDFs escaneados (sem texto) exigem **OCR** (ex.: Tesseract). Habilite com `--ocr` (opcionalmente `--ocr-lang`) ou `ENABLE_OCR=1`/`OCR_LANG`.
- Para lotes grandes (milhares de pÃ¡ginas), rode ingestÃ£o em *batches* e crie o Ã­ndice **depois**.
- Se jÃ¡ usa Postgres no seu stack, pgvector Ã© simples e barato. Se quiser um serviÃ§o dedicado, olhe **Qdrant** ou **Weaviate**.
 
## CritÃ©rios de acessibilidade e desempenho
- Texto alternativo e rÃ³tulos ARIA para componentes interativos.
- NavegaÃ§Ã£o total por teclado e foco visÃ­vel.
- Contraste mÃ­nimo de 4.5:1 nas cores da interface.
- Respostas transmitidas via **SSE** para reduzir latÃªncia.
- Limpeza automÃ¡tica de uploads e limites de tamanho para preservar recursos.

Boa construÃ§Ã£o! ðŸš€
(gerado em 2025-08-18)

## Reranqueamento (BM25)

- A busca agora ocorre em duas etapas: (1) recuperação vetorial via pgvector, (2) reranqueamento léxico com BM25 nos candidatos.
- Benefícios: melhora a precisão do top-K final em consultas curtas/termos específicos, com custo baixo.
- Implementação:
  - O backend busca um conjunto maior (pré-K = `max(k*4, 20)`) e aplica BM25 para ordenar e cortar para `k`.
  - Embeddings: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (mean pooling).
  - Código: `app/rag.py` (`_bm25_rerank` e `build_context`).
- Ajustes: valores são fixos no código; podemos expor variáveis se quiser calibrar `k`/pré-K.

## Feedback de Qualidade

- Endpoint para registrar feedback de respostas e apoiar melhoria contínua.
- Rota: `POST /api/feedback`
- Corpo (JSON):
  - `helpful` (bool): se a resposta ajudou.
  - `question` (string, opcional): pergunta do usuário.
  - `answer` (string, opcional): resposta fornecida.
  - `sessionId` (string, opcional): sessão/conversa.
  - `sources` (json, opcional): fontes citadas (ex.: lista com `path`, `chunk_index`, etc.).
- Exemplo (curl):

```bash
curl -s -X POST http://localhost:8000/api/feedback \
  -H 'Content-Type: application/json' \
  -d '{
    "helpful": true,
    "question": "Como configuro potencia de leitura?",
    "answer": "...",
    "sessionId": "S123",
    "sources": [{"path": "/app/docs/manual.pdf", "chunk_index": 0}]
  }'
```

- Persistência: registros na tabela `feedbacks` (migração `migrations/005_add_feedback_table.sql`).
- Inicialização: o backend garante schema/migrações antes de inserir (idempotente).
- Métricas: simples agregar por `helpful=false`, período (`created_at`) e origem (`session_id`/`sources`). Se quiser, expomos endpoints de agregação.
