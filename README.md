# PDF/Markdown ‚Üí Vector DB (pgvector) Starter Kit

Crie rapidamente uma base de conhecimento a partir de **arquivos PDF** e **Markdown** em uma pasta local e habilite **busca sem√¢ntica** para um agente de IA.

Inclui uma interface web inspirada no ChatGPT com hist√≥rico de conversas, anexos, destaque de c√≥digo e altern√¢ncia de tema claro/escuro.

## Vis√£o geral
1. **Extrai** textos dos PDFs e arquivos Markdown.
2. **Divide** em *chunks* (trechos) com sobreposi√ß√£o.
3. **Gera embeddings** (multil√≠ngue, PT/EN) com `fastembed`.
4. **Armazena** em **PostgreSQL + pgvector**.
5. **Consulta** por similaridade (kNN) com `query.py` ‚Äî pronto para integrar no seu agente.

> Dimens√£o dos vetores: **384** (modelo `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`).

### Suporte a idiomas
O modelo `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` atende mais de 50 idiomas
e foi verificado com frases em **ingl√™s**, **portugu√™s brasileiro** e **espanhol**.
L√≠nguas fora desse conjunto podem gerar embeddings de qualidade reduzida e
resultados menos precisos.

---

## Requisitos
- **Docker** + **Docker Compose** (para o Postgres com pgvector).
- **Python 3.10+** com `pip`.
- *(Opcional p/ OCR)* `tesseract-ocr`, pacotes de idioma (`tesseract-ocr-eng`, `tesseract-ocr-por`, `tesseract-ocr-spa`) e `poppler-utils`.
O `Dockerfile` j√° instala esses pacotes.

## Ambiente de desenvolvimento
1. Clone este reposit√≥rio.
2. Crie um ambiente virtual e instale as depend√™ncias:
```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```
3. Suba o Postgres local com pgvector:
```bash
docker compose up -d db
```
4. Execute os testes para validar o setup:
```bash
pytest
```
5. Inicie o backend em modo `reload`:
```bash
uvicorn app.main:app --reload
```
6. (Opcional) Para a interface web estilo ChatGPT (hist√≥rico, anexos, temas), entre em `frontend/` e rode `npm install && npm run dev`.

## Passo a passo (r√°pido)
```bash
# 1) Suba o Postgres com pgvector
docker compose up -d db

# 2) Instale as depend√™ncias Python
python -m venv .venv && source .venv/bin/activate  # no Windows: .venv\Scripts\activate
pip install -r requirements.txt

# 3) Configure vari√°veis de ambiente (opcional)
cp .env.example .env  # edite se quiser

# 4) Coloque seus PDFs e arquivos Markdown (.md) na pasta ./docs/
#    Arquivos .md nessa pasta s√£o ingeridos junto com os PDFs
#    (ou aponte outra pasta com --docs / DOCS_DIR)

# 5) Ingest√£o
python ingest.py --docs ./docs  # use --ocr (ex.: --ocr-lang eng+por) ou ENABLE_OCR=1 para PDFs escaneados

# 6) Consulta (exemplo)
python query.py --q "Como configuro pot√™ncia de leitura?" --k 5
```

## Ingest√£o de PDFs/Markdown com Docker

1. **Tornar os arquivos acess√≠veis ao container**

   - Coloque os arquivos na pasta `docs/` do projeto.
   - Essa pasta j√° est√° mapeada dentro do container; tudo nela ficar√° dispon√≠vel em `/app/docs` quando o servi√ßo subir.

2. **Ingerir os arquivos no banco**

   No diret√≥rio raiz do projeto, execute:

   ```bash
   docker compose run --rm app python ingest.py --docs /app/docs  # adicione --ocr/--ocr-lang ou ENABLE_OCR=1 se preciso
   ```

   Esse script l√™ os PDFs e arquivos Markdown e grava os vetores no **PostgreSQL/pgvector**.

3. **Subir a aplica√ß√£o**

   Inicie os servi√ßos normalmente:

   ```bash
   docker compose up --build
   ```

   Isso lan√ßa o backend e o frontend, que j√° podem consultar os documentos ingeridos.

4. **(Opcional) Usar outra pasta local**

   Se preferir outra pasta, **antes** de subir os containers, altere o mapeamento de volume em `docker-compose.yml` para apontar para o diret√≥rio desejado.

   Exemplo para Windows:

   ```yaml
   volumes:
     - C:/Users/alexa/Dropbox/Delivery/Impinj/R700/FAQ:/app/docs:ro
   ```

   Depois, rode a ingest√£o:

   ```bash
   docker compose run --rm app python ingest.py --docs /app/docs  # adicione --ocr/--ocr-lang ou ENABLE_OCR=1 se preciso
   ```

   Ou mapeie o volume diretamente na execu√ß√£o:

   ```bash
   docker compose run --rm \
     -v "C:/Users/alexa/Dropbox/Delivery/Impinj/R700/FAQ:/app/docs:ro" \
    app python ingest.py --docs /app/docs  # adicione --ocr ou ENABLE_OCR=1 se preciso
   ```


## Ingest√£o de p√°ginas web p√∫blicas

Al√©m de arquivos locais, o `ingest.py` tamb√©m pode buscar e indexar p√°ginas da web acess√≠veis publicamente.

```bash
# Uma ou mais URLs diretamente na linha de comando
python ingest.py --url https://exemplo.com/sobre --url https://example.com/en/doc

# Lista de URLs (uma por linha)
python ingest.py --urls-file urls.txt
# ou defina URLS_FILE=urls.txt e o script usar√° esse caminho por padr√£o
```

O conte√∫do dessas p√°ginas deve estar em **ingl√™s**, **portugu√™s** ou **espanhol** (EN/PT/ES).

## Logging

A aplica√ß√£o grava dois arquivos de log em `LOG_DIR` (padr√£o `logs/` localmente):

- `app.log` ‚Äì eventos da aplica√ß√£o.
- `access.log` ‚Äì requisi√ß√µes/respostas HTTP.

Os arquivos s√£o **rotacionados diariamente √† meia-noite** e mantidos por `LOG_RETENTION_DAYS` dias (padr√£o: 7).
Defina `LOG_ROTATE_UTC=true` para rotacionar em UTC.

Principais vari√°veis de ambiente:

| Vari√°vel              | Padr√£o    | Descri√ß√£o |
|----------------------|-----------|-----------|
| `LOG_DIR`            | `logs/`   | Diret√≥rio dos arquivos de log (no Docker: `/var/log/app`). |
| `LOG_LEVEL`          | `INFO`    | N√≠vel m√≠nimo de log. |
| `LOG_JSON`           | `false`   | Sa√≠da em formato JSON. |
| `LOG_REQUEST_BODIES` | `false`   | Inclui corpo da requisi√ß√£o no access log. |
| `LOG_RETENTION_DAYS` | `7`       | Quantidade de dias mantidos ap√≥s rota√ß√£o. |
| `LOG_ROTATE_UTC`     | `false`   | Rotaciona usando UTC. |

Para verificar rapidamente os valores efetivos dessas configura√ß√µes, execute:

```bash
python -m tools.print_log_config
```

### Tailing logs

```bash
# Local
tail -f logs/app.log

# Docker
docker compose logs -f app
docker compose exec app tail -f /var/log/app/app.log
```

Para persistir os logs dos containers no host, mapeie um volume:

```yaml
app:
  volumes:
    - ./logs:/var/log/app
```

## M√©tricas

A aplica√ß√£o exp√µe m√©tricas no formato **Prometheus** em `/api/metrics`.
Ao rodar localmente ou via Docker, voc√™ pode verificar as m√©tricas com:

```bash
curl http://localhost:8000/api/metrics
```

Esses dados podem ser coletados por Prometheus ou outras ferramentas de monitoramento.

## Build do chat e frontend

```bash
# Backend standalone
uvicorn app.main:app --reload  # roda em http://localhost:8000

# ou construa tudo com Docker
docker compose up --build

# Frontend (opcional para alterar a interface)
cd frontend
npm install
npm run build  # gera os arquivos em app/static
```

## Vari√°veis de ambiente
Copie `.env.example` para `.env` e ajuste conforme necess√°rio. Exemplo m√≠nimo:

```env
DOCS_DIR=./docs           # PDFs e Markdown (.md) lidos desta pasta
ENABLE_OCR=0              # OCR s√≥ para PDFs escaneados (n√£o afeta .md)
OCR_LANG=eng+por+spa      # ex.: PDFs em ingl√™s, portugu√™s e espanhol
```

Principais chaves dispon√≠veis:

- **PGHOST**, **PGPORT**, **PGDATABASE**, **PGUSER**, **PGPASSWORD** ‚Äì conex√£o com o Postgres/pgvector (padr√µes: `db`, `5432`, `pdfkb`, `pdfkb`, `pdfkb`).
- **DOCS_DIR** ‚Äì pasta padr√£o para os arquivos. Qualquer `.md` nessa pasta √© ingerido junto com os PDFs.
  - **OPENAI_API_KEY**, **OPENAI_MODEL**, **OPENAI_LANG**, **SYSTEM_PROMPT**, **USE_LLM** ‚Äì integra√ß√µes com LLM (opcional). `SYSTEM_PROMPT` permite configurar o tom/persona do agente.
- **TOP_K**, **MAX_CONTEXT_CHARS** ‚Äì ajustes de recupera√ß√£o de trechos.
- **UPLOAD_DIR**, **UPLOAD_TTL**, **UPLOAD_MAX_SIZE**, **UPLOAD_MAX_FILES**, **UPLOAD_ALLOWED_MIME_TYPES** ‚Äì controle de uploads tempor√°rios.
- **CORS_ALLOW_ORIGINS**, **BRAND_NAME**, **POWERED_BY_LABEL**, **LOGO_URL** ‚Äì personaliza√ß√£o da UI. `POWERED_BY_LABEL` define o texto do rodap√© (padr√£o: "Powered by PDF Knowledge Kit").
- **ENABLE_OCR** ‚Äì habilita OCR em execu√ß√µes n√£o interativas (override de `--ocr`).
- **OCR_LANG** ‚Äì idiomas do Tesseract para OCR. Combine m√∫ltiplos c√≥digos com `+` (ex.: `eng+por`).

## OCR (Tesseract)

Por padr√£o, o OCR usa `OCR_LANG=eng+por+spa` (Ingl√™s, Portugu√™s e Espanhol). Altere os idiomas com `--ocr-lang` ou definindo a vari√°vel `OCR_LANG` antes da execu√ß√£o.

### Instala√ß√£o

Para PDFs escaneados, instale o mecanismo de OCR, os pacotes de idioma e os conversores de PDF (o `Dockerfile` j√° inclui `tesseract-ocr-eng`, `tesseract-ocr-por` e `tesseract-ocr-spa`):

```bash
# Ubuntu/Debian
sudo apt install tesseract-ocr tesseract-ocr-eng tesseract-ocr-por tesseract-ocr-spa poppler-utils
# macOS (Homebrew)
brew install tesseract poppler
# Ver idiomas dispon√≠veis
tesseract --list-langs
```

### Como habilitar

- **Linha de comando (override):**

  ```bash
  python ingest.py --ocr --ocr-lang eng --docs ./docs
  ```

- **Vari√°veis de ambiente (override):**

  ```bash
  ENABLE_OCR=1 OCR_LANG=spa+por python ingest.py --docs ./docs
  ```

### Desempenho e suporte a idiomas

- OCR aumenta o tempo de ingest√£o (cada p√°gina √© renderizada e processada).
- `OCR_LANG` e `--ocr-lang` aceitam m√∫ltiplos c√≥digos (ex.: `eng+por+spa`). Cada idioma extra deixa o processamento mais lento, mas pode melhorar a precis√£o em documentos multil√≠ngues; instale os pacotes correspondentes.

### Solu√ß√£o de problemas

- `tesseract: command not found` ou `pdftoppm: command not found` ‚Üí instale `tesseract-ocr` e `poppler-utils` e verifique o `PATH`.
- `Error opening data file` ou `Failed loading language` ‚Üí o pacote de idioma n√£o est√° instalado. Rode `tesseract --list-langs` e instale, por exemplo, `sudo apt install tesseract-ocr-spa`.

## Uso do chat
1. Garanta que o backend esteja rodando (com `uvicorn` ou Docker).
2. Acesse `http://localhost:8000` no navegador.
3. Envie mensagens pelo campo de texto. Opcionalmente, anexe um PDF pequeno para enriquecer o contexto.
4. Durante a gera√ß√£o da resposta, use **Cancelar** para interromper o streaming e **Enviar** novamente para retomar.

Recursos da interface:
- Barra lateral com hist√≥rico de conversas (criar, renomear, excluir).
- Avatares e bolhas com realce de c√≥digo via Prism.
- Bot√µes para copiar, regenerar e avaliar cada resposta.
- Pr√©-visualiza√ß√£o de PDFs anexados.
- Altern√¢ncia entre tema claro e escuro.

## Estrutura
```
pdf_knowledge_kit/
‚îú‚îÄ docker-compose.yml      # Postgres + pgvector
‚îú‚îÄ requirements.txt        # Depend√™ncias
‚îú‚îÄ schema.sql              # Cria√ß√£o de tabelas/√≠ndices
‚îú‚îÄ migrations/             # Migra√ß√µes incrementais do banco de dados
‚îú‚îÄ ingest.py               # Varre PDFs/Markdown, extrai, fatia e insere
‚îú‚îÄ query.py                # Busca sem√¢ntica
‚îú‚îÄ .env.example            # Configs de conex√£o
‚îî‚îÄ docs/                   # Coloque seus PDFs e Markdown aqui
```

## Deploy em produ√ß√£o

### Bare metal
1. Instale **PostgreSQL** com a extens√£o **pgvector** e crie o banco:
```bash
psql -c 'CREATE EXTENSION IF NOT EXISTS vector;' "$PGDATABASE"
psql -f schema.sql "$PGDATABASE"
psql -f migrations/002_add_admin_ingestion.sql "$PGDATABASE"
psql -f migrations/003_extend_ingestion_tables.sql "$PGDATABASE"  # novas colunas de metadados
```
2. Configure as vari√°veis de ambiente (veja `.env.example`).
3. Ingestione os documentos:
```bash
python ingest.py --docs ./docs
```
4. Inicie a API com um servidor como **gunicorn** ou **uvicorn**:
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```
5. Teste:
```bash
curl http://localhost:8000/api/health
```

## Debug com Dev Containers (VS Code)

- Pr√©-requisitos: Docker Desktop; VS Code com extens√£o "Dev Containers"; acesso √† internet para baixar imagens.
- Abrir no container:
  - Abra a pasta do projeto no VS Code.
  - Paleta de Comandos ‚Üí "Dev Containers: Reopen in Container" (ou "Rebuild and Reopen in Container").
  - O VS Code usa `.devcontainer/devcontainer.json` + `docker-compose.yml` e sobe `db`, `app` e `frontend`.
- Aguardar o banco ficar healthy:
  - O servi√ßo `db` fica "healthy" via `pg_isready`; a primeira execu√ß√£o pode demorar por download de imagens.
  - Para um reset completo: `docker compose down -v` e depois `docker compose up -d`.
- Iniciar o debug:
  - Backend: pressione F5 e selecione "Attach to FastAPI (Docker)". O backend j√° inicia com `debugpy` em `0.0.0.0:5678` e `--wait-for-client`, ent√£o ele come√ßa a rodar ap√≥s o attach. Quebre em `app/` normalmente.
  - Full‚Äëstack: selecione "Fullstack: Backend + Frontend" para anexar ao backend e abrir o Vite dev server no navegador.
- Portas √∫teis:
  - API: `http://localhost:8000` (OpenAPI em `/docs`, health em `/api/health`)
  - Frontend: `http://localhost:5173`
  - Debug Python (debugpy): `5678`
- Conex√£o ao Postgres nos containers:
  - Use o host `db` (n√£o `localhost`). A `.env` j√° define `PGHOST=db` e `DATABASE_URL=postgresql://pdfkb:pdfkb@db:5432/pdfkb`.
- Dicas r√°pidas:
  - Logs: `docker compose logs -f db app frontend`
  - Shell no container: `docker compose exec app bash`
  - Reset do banco (apaga volume): `docker compose down -v`

### Docker
1. Copie `.env.example` para `.env` e ajuste.
2. Construa e suba os servi√ßos:
```bash
docker compose up --build -d
```
> Nota (Docker/Dev Containers): dentro dos containers use o host `db` (n√£o `localhost`) para acessar o Postgres. A `.env` j√° define `PGHOST=db` e `DATABASE_URL=postgresql://pdfkb:pdfkb@db:5432/pdfkb`.
3. Ingerir documentos dentro do container:
```bash
docker compose run --rm app python ingest.py --docs /app/docs
```
4. Verifique a API:
```bash
curl http://localhost:8000/api/health
```

## Integra√ß√£o no seu agente de IA (resumo)
- Use `query.py` como refer√™ncia: gere embedding da pergunta e rode SQL:
  `SELECT ... ORDER BY embedding <-> :vec LIMIT :k`.
  - Traga os trechos + metadados e alimente o *prompt* do agente (*RAG*).
  - Para respostas fi√©is, **mostre as fontes** (caminho do arquivo e p√°gina, quando houver).

## Respostas humanizadas com OpenAI

O kit pode complementar os trechos retornados com uma resposta em linguagem natural gerada pela API da OpenAI.

1. Configure as vari√°veis de ambiente:

```bash
export OPENAI_API_KEY="sua-chave"
export OPENAI_MODEL="gpt-4o-mini"  # ou outro modelo compat√≠vel
export OPENAI_LANG="pt"            # opcional: for√ßa o idioma da resposta
```

Se `OPENAI_LANG` n√£o for definido, o idioma da pergunta √© detectado automaticamente e a resposta √© devolvida no mesmo idioma.

### Exemplo (CLI)

```bash
python query.py --q "¬øCu√°l es la capital de Francia?" --k 3
# Resposta: La capital de Francia es Par√≠s.
```

### Exemplo (API)

```bash
curl -s -X POST http://localhost:8000/api/ask \
  -H 'Content-Type: application/json' \
  -d '{"q":"Qual √© a capital da Alemanha?"}'
```

Resposta:

```json
{"answer": "A capital da Alemanha √© Berlim.", "from_llm": true}
```

## Admin Ingestion

The `/api/admin/ingest/*` endpoints let operators trigger ingestion jobs remotely. Jobs run in the background and immediately return a `job_id`. Each job writes its own log file that can be polled while the work proceeds.

### Roles and environment variables

Requests must send an API key in the `X-API-Key` header. Keys map to roles in a strict hierarchy:

- **viewer** ‚Äì read-only access to jobs and sources.
- **operator** ‚Äì all viewer permissions plus start and cancel jobs.
- **admin** ‚Äì reserved for advanced operations.

Configure the keys with single-value environment variables:

```bash
ADMIN_API_KEY=admin    # full access
OP_API_KEY=oper        # start/cancel jobs
VIEW_API_KEY=view      # read-only
```

### Job lifecycle, logs, and monitoring

Jobs move from `pending` ‚Üí `running` ‚Üí `completed`/`failed`/`canceled`. Logs are stored per job and exposed via `GET /api/admin/ingest/jobs/<JOB_ID>/logs`. The endpoint returns a slice of text and the next byte offset so clients can poll to tail progress.

```bash
# List jobs
curl -H "X-API-Key: $VIEWER_API_KEY" \
  http://localhost:8000/api/admin/ingest/jobs

# Inspect a single job
curl -H "X-API-Key: $VIEWER_API_KEY" \
  http://localhost:8000/api/admin/ingest/jobs/<JOB_ID>

# Read logs from the beginning
curl -H "X-API-Key: $VIEWER_API_KEY" \
  "http://localhost:8000/api/admin/ingest/jobs/<JOB_ID>/logs?offset=0"

# Cancel a running job
curl -X POST -H "X-API-Key: $OPERATOR_API_KEY" \
  http://localhost:8000/api/admin/ingest/jobs/<JOB_ID>/cancel

# Re-run a job using the same source
curl -X POST -H "X-API-Key: $OPERATOR_API_KEY" \
  http://localhost:8000/api/admin/ingest/jobs/<JOB_ID>/rerun
```

### Ingestion examples

```bash
# Local file
curl -X POST http://localhost:8000/api/admin/ingest/local \
  -H "X-API-Key: $OPERATOR_API_KEY" \
  -d "path=/app/docs/example.pdf"

# Single URL
curl -X POST http://localhost:8000/api/admin/ingest/url \
  -H "X-API-Key: $OPERATOR_API_KEY" \
  -d "url=https://example.com/doc"

# List of URLs
curl -X POST http://localhost:8000/api/admin/ingest/urls \
  -H "X-API-Key: $OPERATOR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"urls": ["https://a.com/doc1", "https://b.com/doc2"]}'
```

### Source management

```bash
# List known sources
curl -H "X-API-Key: $VIEWER_API_KEY" \
  http://localhost:8000/api/admin/ingest/sources
```

### Admin UI

Admin features live under `frontend/src/admin` inside the main frontend project. To work on them, start the frontend dev server and visit the `/admin` route:

```bash
cd frontend
npm install
npm run dev
```

If you need to serve the UI from another origin, set `ADMIN_UI_ORIGINS` before starting the backend so CORS allows the requests.

## Dicas francas
- PDFs escaneados (sem texto) exigem **OCR** (ex.: Tesseract). Habilite com `--ocr` (opcionalmente `--ocr-lang`) ou `ENABLE_OCR=1`/`OCR_LANG`.
- Para lotes grandes (milhares de p√°ginas), rode ingest√£o em *batches* e crie o √≠ndice **depois**.
- Se j√° usa Postgres no seu stack, pgvector √© simples e barato. Se quiser um servi√ßo dedicado, olhe **Qdrant** ou **Weaviate**.
 
## Crit√©rios de acessibilidade e desempenho
- Texto alternativo e r√≥tulos ARIA para componentes interativos.
- Navega√ß√£o total por teclado e foco vis√≠vel.
- Contraste m√≠nimo de 4.5:1 nas cores da interface.
- Respostas transmitidas via **SSE** para reduzir lat√™ncia.
- Limpeza autom√°tica de uploads e limites de tamanho para preservar recursos.

Boa constru√ß√£o! üöÄ
(gerado em 2025-08-18)
